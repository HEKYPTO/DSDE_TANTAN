{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8374441,"sourceType":"datasetVersion","datasetId":4979054}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Install Library","metadata":{}},{"cell_type":"code","source":"!pip install pyspark","metadata":{"execution":{"iopub.status.busy":"2024-05-10T10:16:22.346372Z","iopub.execute_input":"2024-05-10T10:16:22.346770Z","iopub.status.idle":"2024-05-10T10:17:08.922228Z","shell.execute_reply.started":"2024-05-10T10:16:22.346741Z","shell.execute_reply":"2024-05-10T10:17:08.921100Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting pyspark\n  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\nBuilding wheels for collected packages: pyspark\n  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488493 sha256=6e945da6661da4a452a240816d05913d1317871252c4db76ee6feba517081cc6\n  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\nSuccessfully built pyspark\nInstalling collected packages: pyspark\nSuccessfully installed pyspark-3.5.1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Processing Spark","metadata":{}},{"cell_type":"code","source":"from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, concat, lit, when\nimport os\n\n# Initialize the Spark session\nspark = SparkSession.builder \\\n    .appName(\"DataSciProject\") \\\n    .getOrCreate()","metadata":{"execution":{"iopub.status.busy":"2024-05-10T11:38:29.932702Z","iopub.execute_input":"2024-05-10T11:38:29.933085Z","iopub.status.idle":"2024-05-10T11:38:29.941152Z","shell.execute_reply.started":"2024-05-10T11:38:29.933055Z","shell.execute_reply":"2024-05-10T11:38:29.940170Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# Folder path containing JSON files\nfolder_path = '/kaggle/input/scorpus/2023'\n\n# List all files in the folder\nfiles = [os.path.join(folder_path, file) for file in os.listdir(folder_path)]\n\n# Initialize combined_df as None\nnew_df = None\n\n# Iterate over each file and read it into a DataFrame\nfor file in files:\n    # Read the JSON file into a DataFrame\n    df = spark.read.option(\"multiLine\", \"true\").json(file)\n\n    # Append to combined_df if title and abstract are not empty\n    title = df.select(col(\"abstracts-retrieval-response.item.bibrecord.head.citation-title\").alias(\"title\"))\n    abstract = df.select(col(\"abstracts-retrieval-response.item.bibrecord.head.abstracts\").alias(\"abstract\"))\n    if not title.isEmpty() and not abstract.isEmpty():\n        if new_df is None:\n            new_df = title.union(abstract)\n        else:\n            # Concatenate title and abstract columns into a new column named new_title\n            Title_Abstract = title.select(concat(col(\"title\"), lit(\" \"), col(\"abstract\")).alias(\"Title_Abstract\"))\n            new_df = new_df.union(Title_Abstract)","metadata":{"execution":{"iopub.status.busy":"2024-05-10T11:00:01.463878Z","iopub.execute_input":"2024-05-10T11:00:01.464881Z","iopub.status.idle":"2024-05-10T11:00:23.012776Z","shell.execute_reply.started":"2024-05-10T11:00:01.464838Z","shell.execute_reply":"2024-05-10T11:00:23.011704Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"new_df.coalesce(1).write.csv(path=\"/kaggle/working/cleaned2023\", mode=\"overwrite\", header=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-10T11:04:21.492287Z","iopub.execute_input":"2024-05-10T11:04:21.492937Z","iopub.status.idle":"2024-05-10T11:04:43.600035Z","shell.execute_reply.started":"2024-05-10T11:04:21.492905Z","shell.execute_reply":"2024-05-10T11:04:43.598964Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"# Folder path containing JSON files\nfolder_path = '/kaggle/input/scorpus/2022'\n\n# List all files in the folder\nfiles = [os.path.join(folder_path, file) for file in os.listdir(folder_path)]\n\n# Initialize combined_df as None\nnew_df = None\n\n# Iterate over each file and read it into a DataFrame\nfor file in files:\n    # Read the JSON file into a DataFrame\n    df = spark.read.option(\"multiLine\", \"true\").json(file)\n\n    # Append to combined_df if title and abstract are not empty\n    title = df.select(col(\"abstracts-retrieval-response.item.bibrecord.head.citation-title\").alias(\"title\"))\n    abstract = df.select(col(\"abstracts-retrieval-response.item.bibrecord.head.abstracts\").alias(\"abstract\"))\n    if not title.isEmpty() and not abstract.isEmpty():\n        if new_df is None:\n            new_df = title.union(abstract)\n        else:\n            # Concatenate title and abstract columns into a new column named new_title\n            Title_Abstract = title.select(concat(col(\"title\"), lit(\" \"), col(\"abstract\")).alias(\"Title_Abstract\"))\n            new_df = new_df.union(Title_Abstract)","metadata":{"execution":{"iopub.status.busy":"2024-05-10T11:07:55.155992Z","iopub.execute_input":"2024-05-10T11:07:55.156390Z","iopub.status.idle":"2024-05-10T11:08:40.418317Z","shell.execute_reply.started":"2024-05-10T11:07:55.156359Z","shell.execute_reply":"2024-05-10T11:08:40.417296Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"new_df.coalesce(1).write.csv(path=\"/kaggle/working/cleaned2022\", mode=\"overwrite\", header=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-10T11:08:44.532083Z","iopub.execute_input":"2024-05-10T11:08:44.532465Z","iopub.status.idle":"2024-05-10T11:09:26.629922Z","shell.execute_reply.started":"2024-05-10T11:08:44.532423Z","shell.execute_reply":"2024-05-10T11:09:26.628912Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"# Folder path containing JSON files\nfolder_path = '/kaggle/input/scorpus/2021'\n\n# List all files in the folder\nfiles = [os.path.join(folder_path, file) for file in os.listdir(folder_path)]\n\n# Initialize combined_df as None\nnew_df = None\n\n# Iterate over each file and read it into a DataFrame\nfor file in files:\n    # Read the JSON file into a DataFrame\n    df = spark.read.option(\"multiLine\", \"true\").json(file)\n\n    # Append to combined_df if title and abstract are not empty\n    title = df.select(col(\"abstracts-retrieval-response.item.bibrecord.head.citation-title\").alias(\"title\"))\n    abstract = df.select(col(\"abstracts-retrieval-response.item.bibrecord.head.abstracts\").alias(\"abstract\"))\n    if not title.isEmpty() and not abstract.isEmpty():\n        if new_df is None:\n            new_df = title.union(abstract)\n        else:\n            # Concatenate title and abstract columns into a new column named new_title\n            Title_Abstract = title.select(concat(col(\"title\"), lit(\" \"), col(\"abstract\")).alias(\"Title_Abstract\"))\n            new_df = new_df.union(Title_Abstract)","metadata":{"execution":{"iopub.status.busy":"2024-05-10T11:43:18.458485Z","iopub.execute_input":"2024-05-10T11:43:18.459213Z","iopub.status.idle":"2024-05-10T11:43:46.065867Z","shell.execute_reply.started":"2024-05-10T11:43:18.459182Z","shell.execute_reply":"2024-05-10T11:43:46.064941Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"new_df.coalesce(1).write.csv(path=\"/kaggle/working/cleaned2021\", mode=\"overwrite\", header=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-10T11:43:56.755159Z","iopub.execute_input":"2024-05-10T11:43:56.755545Z","iopub.status.idle":"2024-05-10T11:44:34.064078Z","shell.execute_reply.started":"2024-05-10T11:43:56.755515Z","shell.execute_reply":"2024-05-10T11:44:34.063052Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"# Folder path containing JSON files\nfolder_path = '/kaggle/input/scorpus/2020'\n\n# List all files in the folder\nfiles = [os.path.join(folder_path, file) for file in os.listdir(folder_path)]\n\n# Initialize combined_df as None\nnew_df = None\n\n# Iterate over each file and read it into a DataFrame\nfor file in files:\n    # Read the JSON file into a DataFrame\n    df = spark.read.option(\"multiLine\", \"true\").json(file)\n\n    # Append to combined_df if title and abstract are not empty\n    title = df.select(col(\"abstracts-retrieval-response.item.bibrecord.head.citation-title\").alias(\"title\"))\n    abstract = df.select(col(\"abstracts-retrieval-response.item.bibrecord.head.abstracts\").alias(\"abstract\"))\n    if not title.isEmpty() and not abstract.isEmpty():\n        if new_df is None:\n            new_df = title.union(abstract)\n        else:\n            # Concatenate title and abstract columns into a new column named new_title\n            Title_Abstract = title.select(concat(col(\"title\"), lit(\" \"), col(\"abstract\")).alias(\"Title_Abstract\"))\n            new_df = new_df.union(Title_Abstract)","metadata":{"execution":{"iopub.status.busy":"2024-05-10T11:45:05.197854Z","iopub.execute_input":"2024-05-10T11:45:05.198224Z","iopub.status.idle":"2024-05-10T11:46:08.786655Z","shell.execute_reply.started":"2024-05-10T11:45:05.198194Z","shell.execute_reply":"2024-05-10T11:46:08.785786Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"new_df.coalesce(1).write.csv(path=\"/kaggle/working/cleaned2020\", mode=\"overwrite\", header=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-10T11:46:26.384687Z","iopub.execute_input":"2024-05-10T11:46:26.385047Z","iopub.status.idle":"2024-05-10T11:47:12.612353Z","shell.execute_reply.started":"2024-05-10T11:46:26.385020Z","shell.execute_reply":"2024-05-10T11:47:12.611329Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"# Folder path containing JSON files\nfolder_path = '/kaggle/input/scorpus/2019'\n\n# List all files in the folder\nfiles = [os.path.join(folder_path, file) for file in os.listdir(folder_path)]\n\n# Initialize combined_df as None\nnew_df = None\n\n# Iterate over each file and read it into a DataFrame\nfor file in files:\n    # Read the JSON file into a DataFrame\n    df = spark.read.option(\"multiLine\", \"true\").json(file)\n\n    # Append to combined_df if title and abstract are not empty\n    title = df.select(col(\"abstracts-retrieval-response.item.bibrecord.head.citation-title\").alias(\"title\"))\n    abstract = df.select(col(\"abstracts-retrieval-response.item.bibrecord.head.abstracts\").alias(\"abstract\"))\n    if not title.isEmpty() and not abstract.isEmpty():\n        if new_df is None:\n            new_df = title.union(abstract)\n        else:\n            # Concatenate title and abstract columns into a new column named new_title\n            Title_Abstract = title.select(concat(col(\"title\"), lit(\" \"), col(\"abstract\")).alias(\"Title_Abstract\"))\n            new_df = new_df.union(Title_Abstract)","metadata":{"execution":{"iopub.status.busy":"2024-05-10T11:47:16.670792Z","iopub.execute_input":"2024-05-10T11:47:16.671151Z","iopub.status.idle":"2024-05-10T11:48:04.926112Z","shell.execute_reply.started":"2024-05-10T11:47:16.671121Z","shell.execute_reply":"2024-05-10T11:48:04.925082Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"new_df.coalesce(1).write.csv(path=\"/kaggle/working/cleaned2019\", mode=\"overwrite\", header=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-10T11:48:17.789435Z","iopub.execute_input":"2024-05-10T11:48:17.790162Z","iopub.status.idle":"2024-05-10T11:49:00.789034Z","shell.execute_reply.started":"2024-05-10T11:48:17.790125Z","shell.execute_reply":"2024-05-10T11:49:00.787903Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"# Folder path containing JSON files\nfolder_path = '/kaggle/input/scorpus/2018'\n\n# List all files in the folder\nfiles = [os.path.join(folder_path, file) for file in os.listdir(folder_path)]\n\n# Initialize combined_df as None\nnew_df = None\n\n# Iterate over each file and read it into a DataFrame\nfor file in files:\n    # Read the JSON file into a DataFrame\n    df = spark.read.option(\"multiLine\", \"true\").json(file)\n\n    # Append to combined_df if title and abstract are not empty\n    title = df.select(col(\"abstracts-retrieval-response.item.bibrecord.head.citation-title\").alias(\"title\"))\n    abstract = df.select(col(\"abstracts-retrieval-response.item.bibrecord.head.abstracts\").alias(\"abstract\"))\n    if not title.isEmpty() and not abstract.isEmpty():\n        if new_df is None:\n            new_df = title.union(abstract)\n        else:\n            # Concatenate title and abstract columns into a new column named new_title\n            Title_Abstract = title.select(concat(col(\"title\"), lit(\" \"), col(\"abstract\")).alias(\"Title_Abstract\"))\n            new_df = new_df.union(Title_Abstract)","metadata":{"execution":{"iopub.status.busy":"2024-05-10T11:49:09.241729Z","iopub.execute_input":"2024-05-10T11:49:09.242392Z","iopub.status.idle":"2024-05-10T11:49:57.628549Z","shell.execute_reply.started":"2024-05-10T11:49:09.242360Z","shell.execute_reply":"2024-05-10T11:49:57.627505Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"new_df.coalesce(1).write.csv(path=\"/kaggle/working/cleaned2018\", mode=\"overwrite\", header=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-10T11:50:05.367876Z","iopub.execute_input":"2024-05-10T11:50:05.368240Z","iopub.status.idle":"2024-05-10T11:50:42.288509Z","shell.execute_reply.started":"2024-05-10T11:50:05.368212Z","shell.execute_reply":"2024-05-10T11:50:42.287552Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]}]}