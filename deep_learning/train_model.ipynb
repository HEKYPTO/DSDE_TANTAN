{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCOPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -U bertopic safetensors flash_attn pandas numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!wget -nc https://raw.githubusercontent.com/Songblabla/datasci/main/DSDE_Project-main/clean2023.csv\n",
    "!wget -nc https://raw.githubusercontent.com/Songblabla/datasci/main/DSDE_Project-main/clean2022.csv\n",
    "!wget -nc https://raw.githubusercontent.com/Songblabla/datasci/main/DSDE_Project-main/clean2021.csv\n",
    "!wget -nc https://raw.githubusercontent.com/Songblabla/datasci/main/DSDE_Project-main/clean2020.csv\n",
    "!wget -nc https://raw.githubusercontent.com/Songblabla/datasci/main/DSDE_Project-main/clean2019.csv\n",
    "!wget -nc https://raw.githubusercontent.com/Songblabla/datasci/main/DSDE_Project-main/clean2018.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df2023 = pd.read_csv(\"clean2023.csv\")\n",
    "df2022 = pd.read_csv(\"clean2022.csv\")\n",
    "df2021 = pd.read_csv(\"clean2021.csv\")\n",
    "df2020 = pd.read_csv(\"clean2020.csv\")\n",
    "df2019 = pd.read_csv(\"clean2019.csv\")\n",
    "df2018 = pd.read_csv(\"clean2018.csv\")\n",
    "\n",
    "dfs = [df2023, df2022, df2021, df2020, df2019, df2018]\n",
    "df = pd.concat(dfs)\n",
    "\n",
    "docs = list(df[\"Title_Abstract\"].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medium Alibaba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"BERTOPIC_MEDBLAST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(\"Alibaba-NLP/gte-large-en-v1.5\", trust_remote_code=True)\n",
    "\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=embedding_model,\n",
    "    verbose=True,\n",
    ")\n",
    "embeddings = embedding_model.encode(docs, batch_size=32, show_progress_bar=True)\n",
    "topics, probs = topic_model.fit_transform(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = topic_model.get_topic_info()\n",
    "freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq.to_csv(f\"{MODEL_NAME}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"Document\": docs, \"Topic\": topic_model.topics_})\n",
    "result.to_csv(f\"{MODEL_NAME}-pred.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"{MODEL_NAME}-embedded.npy\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.save(f\"{MODEL_NAME}\", serialization=\"safetensors\", save_ctfidf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"BERTOPIC_LANGCAST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def get_detailed_instruct(task_description: str, query: str) -> str:\n",
    "    return f'Instruct: {task_description}\\nQuery: {query}'\n",
    "\n",
    "task = \"\"\"\n",
    "Create a system to summarize and classify documents from the Scopus dataset. Develop a model that can accurately categorize documents into types such as research articles, conference papers, and review papers. Additionally, implement a method to generate concise summaries of the documents to aid in quick comprehension and retrieval of key information.\n",
    "\"\"\"\n",
    "queries = [\n",
    "    get_detailed_instruct(task, \"Identify distinguishing features for each document type in the Scopus dataset.\"),\n",
    "    get_detailed_instruct(task, \"Implement a summarization technique to generate brief summaries of the documents.\"),\n",
    "]\n",
    "\n",
    "input_texts = queries + docs\n",
    "\n",
    "model = SentenceTransformer('intfloat/multilingual-e5-large-instruct')\n",
    "\n",
    "embeddings = model.encode(input_texts, batch_size=4, normalize_embeddings=True, show_progress_bar=True)\n",
    "\n",
    "topic_model = BERTopic(verbose=True, embedding_model=model)\n",
    "\n",
    "topics, probs = topic_model.fit_transform(docs, embeddings[len(queries):]) # NO Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = topic_model.get_topic_info()\n",
    "freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq.to_csv(f\"{MODEL_NAME}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"Document\": docs, \"Topic\": topic_model.topics_})\n",
    "result.to_csv(f\"{MODEL_NAME}-pred.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"{MODEL_NAME}-embedded.npy\", embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALL MET BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"BERTOPIC_MET_BASE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=embedding_model,\n",
    "    verbose=True,\n",
    ")\n",
    "embeddings = embedding_model.encode(docs, show_progress_bar=True)\n",
    "topics, probs = topic_model.fit_transform(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = topic_model.get_topic_info()\n",
    "freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq.to_csv(f\"{MODEL_NAME}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"Document\": docs, \"Topic\": topic_model.topics_})\n",
    "result.to_csv(f\"{MODEL_NAME}-pred.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"{MODEL_NAME}-embedded.npy\", embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MINI LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"BERTOPIC_MINI_RAILS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer('llmrails/ember-v1')\n",
    "\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=embedding_model,\n",
    "    verbose=True,\n",
    ")\n",
    "embeddings = embedding_model.encode(docs, batch_size=4, show_progress_bar=True)\n",
    "topics, probs = topic_model.fit_transform(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = topic_model.get_topic_info()\n",
    "freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq.to_csv(f\"{MODEL_NAME}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"Document\": docs, \"Topic\": topic_model.topics_})\n",
    "result.to_csv(f\"{MODEL_NAME}-pred.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"{MODEL_NAME}-embedded.npy\", embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALL MET + SUMMARIZER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This is the best of the balance results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"BERTOPIC_MET_FLAN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-large\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-large\", device_map=\"auto\")\n",
    "\n",
    "def summarization_model(text):\n",
    "    input_text = f\"Identify unique topics in this Nature document given here: {docs[0]}.\"\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "\n",
    "    outputs = model.generate(input_ids)\n",
    "    return tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic.representation._base import BaseRepresentation\n",
    "from typing import List, Mapping, Tuple\n",
    "\n",
    "class SummarizationRepresentation(BaseRepresentation):\n",
    "    def __init__(self, summarization_model, summarization_tokenizer):\n",
    "        self.summarization_model = summarization_model\n",
    "        self.summarization_tokenizer = summarization_tokenizer\n",
    "\n",
    "    def extract_topics(self, topic_model, documents, c_tf_idf, topics\n",
    "                      ) -> Mapping[str, List[Tuple[str, float]]]:\n",
    "        updated_topics = {}\n",
    "        for topic_id, words in topics.items():\n",
    "            # Extract only the words from the tuples\n",
    "            words_only = [word[0] for word in words]\n",
    "            text = \" \".join(words_only)\n",
    "            summary = summarization_model(text)\n",
    "            updated_topics[topic_id] = [(summary, 1.0)]\n",
    "        return updated_topics\n",
    "\n",
    "summarization = SummarizationRepresentation(summarization_model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from bertopic.representation import PartOfSpeech, KeyBERTInspired, MaximalMarginalRelevance\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "embedding_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "representation_models = {\n",
    "    \"KeyBERTInspired\": KeyBERTInspired(),\n",
    "    \"Summarization\": [KeyBERTInspired(), summarization],\n",
    "}\n",
    "\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=embedding_model,\n",
    "    representation_model=representation_models,\n",
    "    verbose=True,\n",
    ")\n",
    "embeddings = embedding_model.encode(docs, show_progress_bar=True)\n",
    "topics, probs = topic_model.fit_transform(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = topic_model.get_topic_info()\n",
    "freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq.to_csv(f\"{MODEL_NAME}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"Document\": docs, \"Topic\": topic_model.topics_})\n",
    "result.to_csv(f\"{MODEL_NAME}-pred.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"{MODEL_NAME}-embedded.npy\", embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUGGING_FACE_USERNAME = \"username\"\n",
    "MODEL_NAME = \"BERTOPIC_MET_BLAST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.push_to_hf_hub(\n",
    "    repo_id=f\"{HUGGING_FACE_USERNAME}/{MODEL_NAME}\",\n",
    "    save_ctfidf=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
